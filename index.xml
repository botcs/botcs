<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Botos Csaba on Botos Csaba</title>
    <link>https://users.itk.ppke.hu/~botcs/about/</link>
    <description>Recent content in Botos Csaba on Botos Csaba</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Sun, 15 Oct 2017 00:00:00 +0200</lastBuildDate>
    <atom:link href="/~botcs/about/" rel="self" type="application/rss+xml" />
    
    <item>
      <title></title>
      <link>https://users.itk.ppke.hu/~botcs/about/misc/longbio/</link>
      <pubDate>Wed, 20 Apr 2016 00:00:00 +0200</pubDate>
      
      <guid>https://users.itk.ppke.hu/~botcs/about/misc/longbio/</guid>
      <description>

&lt;h2 id=&#34;bio&#34;&gt;Bio&lt;/h2&gt;

&lt;p&gt;As an undergraduate at PPCU I have interned at the Hungarian Academy of Sciences
where I studied tomographic reconstruction techniques of nervous tissues in the &lt;a href=&#34;http://koki.hu/~nyiri/&#34; target=&#34;_blank&#34;&gt;WQFA&lt;/a&gt;.
After the internship I have drifted from neuroscience towards computer science, neural networks in particular,
and written a toy ConvNet library using only NumPy.
Later on, to reveal effectiveness of the framework I carried out case studies concerning speech recognition, image description, auto-encoders, GANs and most importantly visualization of generating adversarial samples.&lt;/p&gt;

&lt;p&gt;My interest in neuroscience and applied mathematics frankly have been strengthened by tackling &lt;strong&gt;real&lt;/strong&gt; life problems, such as detecting cardiac disorders, where I became familiar with the classic deep learning libraries
Next year we have won the Students&amp;rsquo; Scientific Associations 1st prize with the team I joined for the Challenge for &lt;a href=&#34;https://www.cinc2017.org/&#34; target=&#34;_blank&#34;&gt;Computing in Cardiology 2017&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;In 2018, I graduated as a bionic engineer with honors.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Local phase encoding (DRAFT)</title>
      <link>https://users.itk.ppke.hu/~botcs/about/project/2d-fft/</link>
      <pubDate>Tue, 08 May 2018 01:01:19 +0200</pubDate>
      
      <guid>https://users.itk.ppke.hu/~botcs/about/project/2d-fft/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Atrial fibrillation detection</title>
      <link>https://users.itk.ppke.hu/~botcs/about/project/physionet/</link>
      <pubDate>Tue, 08 May 2018 00:51:25 +0200</pubDate>
      
      <guid>https://users.itk.ppke.hu/~botcs/about/project/physionet/</guid>
      <description></description>
    </item>
    
    <item>
      <title>PPCU Sam</title>
      <link>https://users.itk.ppke.hu/~botcs/about/project/sam/</link>
      <pubDate>Tue, 08 May 2018 00:04:36 +0200</pubDate>
      
      <guid>https://users.itk.ppke.hu/~botcs/about/project/sam/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Dense 3D reconstruction with autonomous agents (DRAFT)</title>
      <link>https://users.itk.ppke.hu/~botcs/about/project/coop-drl-3d/</link>
      <pubDate>Tue, 08 May 2018 00:00:50 +0200</pubDate>
      
      <guid>https://users.itk.ppke.hu/~botcs/about/project/coop-drl-3d/</guid>
      <description>&lt;p&gt;Combine &lt;a href=&#34;http://vladlen.info/publications/semi-parametric-topological-memory-navigation/&#34; target=&#34;_blank&#34;&gt;Intel&amp;rsquo;s navigation&lt;/a&gt;
with &lt;a href=&#34;https://blog.openai.com/learning-to-cooperate-compete-and-communicate/&#34; target=&#34;_blank&#34;&gt;OpenAI cooperative agents&lt;/a&gt;
on &lt;a href=&#34;http://www.robots.ox.ac.uk/~tvg/projects/CollaborativeSLAM/index.php&#34; target=&#34;_blank&#34;&gt;Collaborative Dense recognition task&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Manifold reconstruction (DRAFT)</title>
      <link>https://users.itk.ppke.hu/~botcs/about/project/coop-drl/</link>
      <pubDate>Tue, 08 May 2018 00:00:50 +0200</pubDate>
      
      <guid>https://users.itk.ppke.hu/~botcs/about/project/coop-drl/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;DeepMind parallel agent optim.&lt;/li&gt;
&lt;li&gt;where originally with Wasserstein GAN we would like to reduce the earth mover&amp;rsquo;s distance&lt;/li&gt;
&lt;li&gt;in order to approximate such function we have to enforce Lipschitz property&lt;/li&gt;
&lt;li&gt;to do so we can use weight clipping -&amp;gt; Bad &amp;hellip;&lt;/li&gt;
&lt;li&gt;or gradient penalty -&amp;gt; globally wrong, locally ok&lt;/li&gt;
&lt;li&gt;Why not use TVG collaborative reconstruction on the latent space&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Improve 3D scene reconstruction by semantic mesh generation or factorization (DRAFT)</title>
      <link>https://users.itk.ppke.hu/~botcs/about/project/meshrec/</link>
      <pubDate>Mon, 07 May 2018 23:41:17 +0200</pubDate>
      
      <guid>https://users.itk.ppke.hu/~botcs/about/project/meshrec/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Palace of Wonders</title>
      <link>https://users.itk.ppke.hu/~botcs/about/project/csopa/</link>
      <pubDate>Mon, 07 May 2018 20:04:21 +0200</pubDate>
      
      <guid>https://users.itk.ppke.hu/~botcs/about/project/csopa/</guid>
      <description>

&lt;p&gt;Five AI workshop sessions throughout the 2017-2018 academic year on recent advances in Deep Learning and its applications.&lt;/p&gt;

&lt;h2 id=&#34;motivation&#34;&gt;Motivation&lt;/h2&gt;

&lt;p&gt;The goal of these workshops is to dismiss fear and ignorance in people who are concerned about AI by showing true potential and downsides, possibilities and requirements of current state of the art algorithms.
I wanted demistify the black magic done by tech giants by showing interactive demos of actual AI tools (e.g. pose-detection, voice-recognition, text2image synthesis) and let the audience come up with applications that would be built on top of it, to drive their curiosity in AI towards real questions.&lt;/p&gt;

&lt;p&gt;For further information on these workshops see talks:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:1313/talk/pow1/&#34; target=&#34;_blank&#34;&gt;Let&amp;rsquo;s use our brains&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:1313/talk/pow2/&#34; target=&#34;_blank&#34;&gt;Machines learning on their own&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:1313/talk/pow3/&#34; target=&#34;_blank&#34;&gt;Why do you beat yourself?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:1313/talk/pow4/&#34; target=&#34;_blank&#34;&gt;&amp;ldquo;What I cannot create, I do not understand&amp;rdquo;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:1313/talk/pow5/&#34; target=&#34;_blank&#34;&gt;What would Prometheus bring today?&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>I&#39;m a bionic engineer so what?</title>
      <link>https://users.itk.ppke.hu/~botcs/about/post/im-bionic/</link>
      <pubDate>Mon, 07 May 2018 16:10:18 +0200</pubDate>
      
      <guid>https://users.itk.ppke.hu/~botcs/about/post/im-bionic/</guid>
      <description>

&lt;p&gt;For me, beauty of real world problems is there is no such thing as &lt;em&gt;the best way&lt;/em&gt; to solve them.
It&amp;rsquo;s only up to inhabitants to compete and try anything possible.
I&amp;rsquo;m happy that I&amp;rsquo;ve born in such a time, where nature have come up already with brilliant solutions and people have started to realize their true potential.
Bionic engineering means not only the profession of observing my environment, but the thrive to distill it to applicable ideas.&lt;/p&gt;

&lt;h2 id=&#34;motivation&#34;&gt;Motivation&lt;/h2&gt;

&lt;p&gt;In the last couple of years I&amp;rsquo;ve came across many breathtaking advances in machine learning.
&lt;strong&gt;Aha! moments&lt;/strong&gt; turned out to be really addictive since my first years at PPCU, while I got more and more familiar with the actual content behind the buzzword of deep learning.
When my advisor told me about neural networks I have found a very pleasing position in time and space where both my interest in neuroscience and skills in computer science came handy.
Practically the good part is that there is a brain-inspired system I can build, train and hopefully understand, while the best part is that there are no lives required to sacrifice for science but mine.&lt;/p&gt;

&lt;h2 id=&#34;we-should-follow-nature-s-suggestions-1&#34;&gt;We should follow nature&amp;rsquo;s suggestions&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;:&lt;/h2&gt;

&lt;p&gt;In exchange for my good experiences with the field of machine learning I am truly devoted to publish my observations and commitments in the clearest, most digestable form I can achieve.
Hopefully the project proposals listed below will find novel paths to improving either state of the art algorithms or our understanding of the clockworks inside skulls.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://users.itk.ppke.hu/~botcs/about/project/attention/&#34;&gt;Temporal Attention mechanism&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://users.itk.ppke.hu/~botcs/about/project/nextplease/&#34;&gt;Next Please&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://users.itk.ppke.hu/~botcs/about/project/meshrec/&#34;&gt;Look closer (DRAFT)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://users.itk.ppke.hu/~botcs/about/project/coop-drl-3d/&#34;&gt;Dense 3D reconstruction with autonomous agents (DRAFT)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://users.itk.ppke.hu/~botcs/about/project/coop-drl/&#34;&gt;Manifold reconstruction (DRAFT)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://users.itk.ppke.hu/~botcs/about/project/2d-fft&#34;&gt;Local phase encoding (DRAFT)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;Neuroscience in neural networks is a win-win, keep it that way.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:1&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Next please</title>
      <link>https://users.itk.ppke.hu/~botcs/about/project/nextplease/</link>
      <pubDate>Sun, 06 May 2018 19:43:21 +0200</pubDate>
      
      <guid>https://users.itk.ppke.hu/~botcs/about/project/nextplease/</guid>
      <description>

&lt;p&gt;If I think about how the number of neural connections (the synapse density) changes w.r.t the age in general I would naively say that the older we get, the more knowledge we have and even if the number of neurons decreases that knowledge is expressed in connections between nerve cells, therefore the total number of connections had to increase, or at least stagnate. However ontogenesis studies tells us a different story&amp;hellip;
&lt;img src=&#34;http://ww2.kqed.org/mindshift/wp-content/uploads/sites/23/2016/11/gray-matter-over-time.png&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;https://users.itk.ppke.hu/~botcs/about/img/numofsynapse.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The main thing that I recognise is -mathematically speaking- the decreasing complexity of the connectivity graph of the nervous tissue after the first year of birth. So to say, it is not required to have larger and larger brains to understand more and more complex ideas, that is not how our &lt;em&gt;processor&lt;/em&gt; works.&lt;/p&gt;

&lt;p&gt;On the contrary, in the &lt;a href=&#34;https://icml.cc/2016/tutorials/icml2016_tutorial_deep_residual_networks_kaiminghe.pdf&#34; target=&#34;_blank&#34;&gt;Revolution of Depth&lt;/a&gt; it is mockingly said that the deep residual learning have the following perks:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Ultra deep networks can be easy to train&lt;/li&gt;
&lt;li&gt;Ultra deep networks can gain accuracy from depth&lt;/li&gt;
&lt;li&gt;Ultra deep representations are well transferrable&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So why do we even bother mimicking the nature when we have already found a set of architectures that seem to be gaining power from what should cause higher degrees of instability?
There&amp;rsquo;s an upperbound, and it is the computation capacity.
As long as we have cool big brothers like research groups at Google, Facebook, Microsoft, etc. who publish the trained weights of these huge networks there is no pressure on research labs with a bit more modest equipment to come up with better solutions.
Of course on edge devices, i.e. embedded systems ResNets are still a rare choice - but at least neural networks are considered&amp;hellip;
So it is up to us whether we would follow the footprints of giants or use our resources more wisely.&lt;/p&gt;

&lt;h2 id=&#34;pleasing-or-working-model&#34;&gt;Pleasing or working model?&lt;/h2&gt;

&lt;p&gt;One historical constraint of the multi layer perceptron model on discarding every connections but locals have kickstarted deep learning, namely the &lt;a href=&#34;http://yann.lecun.com/exdb/publis/pdf/lecun-bengio-95a.pdf&#34; target=&#34;_blank&#34;&gt;Convolutional networks&lt;/a&gt;.
Professor Fai Ma have proposed heavier constraints on visual feature extraction.
When I asked him, why should we hardwire frequent geometric shapes of urban scenes into otherwise more general neural networks, what if we had to train it to navigate an agent in a jungle, he pointed out: we have to decide whether we want a mathematically pleasing or a working model. Theoretically even the MLPs could have learned convolutions on their own (since ConvNets are just a special kind of MLPs), or even residual connections.
Still we use the a presume that the input space mainly holds spatial features so we hardwire this information in convnets, and use convnets for images, and use MLPs e.g. for ads.&lt;/p&gt;

&lt;p&gt;If we are too busy for hardwiring our domain specific a priori knowledge into the architectures &lt;code&gt;AND&lt;/code&gt; we posses several thousand TPUs we can throw a non-differentiable evolution algorithm on the problem of defining the computational graph. Quoc Le&amp;rsquo;s group exactly did this to produce state of the art classifiers on CIFAR-10, mobile ImageNet and ImageNet. See &lt;em&gt;Figure 2, g)&lt;/em&gt; in &lt;a href=&#34;https://arxiv.org/abs/1802.01548&#34; target=&#34;_blank&#34;&gt;Regularized Evolution for Image Classifier Architecture Search&lt;/a&gt; for example computation graphs of the unleashed &lt;em&gt;AmoebaNet&lt;/em&gt;
&lt;img src=&#34;https://users.itk.ppke.hu/~botcs/about/img/amoeba.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Now if we take the recent trend of reducing the architecture&amp;rsquo;s complexity by forking the information flow and reducing our search space to functions of more sparse connections like (far from exhaustive listing):&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Szegedy_Going_Deeper_With_2015_CVPR_paper.pdf&#34; target=&#34;_blank&#34;&gt;LeNet: Inception modules&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1602.07360&#34; target=&#34;_blank&#34;&gt;SqueezeNet&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1611.05431&#34; target=&#34;_blank&#34;&gt;ResNext&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1803.10615&#34; target=&#34;_blank&#34;&gt;SqueezeNext&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://users.itk.ppke.hu/~botcs/about/img/nextplease.svg&#34; alt=&#34;&#34; /&gt;
A clever idea based on the effectiveness of parallel threads is improving the generalization ability of multi-branch networks by replacing the standard summation of parallel branches with a stochastic affine combination, presented in &lt;a href=&#34;https://arxiv.org/abs/1705.07485&#34; target=&#34;_blank&#34;&gt;Shake-Shake regularization&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;proposal&#34;&gt;Proposal&lt;/h2&gt;

&lt;p&gt;I think it would be a good idea to apply &lt;em&gt;regularized evolution search&lt;/em&gt; but on a more narrow search space of functions where the underlying architecture would be given and the search would be in set of points of &lt;code&gt;forks&lt;/code&gt;, &lt;code&gt;merges&lt;/code&gt; and &lt;code&gt;skip connections&lt;/code&gt; of the computational graph. Ideally the resulting training would have some sort of freedom in deciding the hyperparameters and hopefully the broken symmetry would reduce singularities described by &lt;a href=&#34;https://arxiv.org/abs/1701.09175&#34; target=&#34;_blank&#34;&gt;Orhan et al.&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Temporal Attention mechanism</title>
      <link>https://users.itk.ppke.hu/~botcs/about/project/attention/</link>
      <pubDate>Sun, 06 May 2018 19:43:21 +0200</pubDate>
      
      <guid>https://users.itk.ppke.hu/~botcs/about/project/attention/</guid>
      <description>

&lt;p&gt;The general idea of thalamo-cortico-thalamo circuitry in vertebrae was against the traditional description of the thalamus being a simple relay of visual information between the eyes and the visual cortex.
In an &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pubmed/12611977&#34; target=&#34;_blank&#34;&gt;experiment&lt;/a&gt; it was shown, that if the connections were inhibited between other cortices aside from the visual resulted in losing of sight - which implied in the first case the revision of the original hypothesis.
To sum up &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2626162/&#34; target=&#34;_blank&#34;&gt;what we know so far&lt;/a&gt;, it is believed additional connections to other parts add both &lt;em&gt;low level&lt;/em&gt; contextual information, such as proprioception and &lt;em&gt;high level&lt;/em&gt; information like enhancing semantic edges of objects, correction based on temporal continuity, etc. that may alter the perception dramatically.
asdasdasd
&lt;img src=&#34;TCT.svgasdasd&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;motivation&#34;&gt;Motivation&lt;/h2&gt;

&lt;p&gt;What I have found appealing in the paper &lt;a href=&#34;https://openreview.net/forum?id=HyzbhfWRW&#34; target=&#34;_blank&#34;&gt;Learn to pay attention&lt;/a&gt; is the main intuition that intermediate activations should be constrained to preserve information for classification.
I thought this was implicitly happening already inside the trained neural networks, however it seems that introducing (learned or hand-crafted) attention mechanism to almost any kind of differentiable architectures enhances the space of learnable functions, mainly by smoothing the loss surface.
Basically by allowing the intermediate cells or layers to contribute to the latent representation vector will follow a similar scenario:
&lt;img src=&#34;https://users.itk.ppke.hu/~botcs/about/img/skip-loss.png&#34; alt=&#34;&#34; /&gt;
This phenomenon is generally described in &lt;a href=&#34;singularity&#34; target=&#34;_blank&#34;&gt;Skip connections eliminate singularities&lt;/a&gt;, stating that:
&amp;ldquo;If the singularity elimination hypothesis is correct, there should be nothing special about identity skip connections. Skip connections other than identity should lead to training improvements if they eliminate singularities.&amp;rdquo;
Furthermore, as it was described in the main article&amp;rsquo;s &lt;em&gt;5.2 Robustness to adversarial attack&lt;/em&gt; the feature extractor finetuned with this additional attention module became less likely to be fooled by some high frequency noise pattern on the original image is a straightforward consequence of stabilized training introduced by skip connection.&lt;/p&gt;

&lt;p&gt;On the other hand I believe that effectivenes of the specific skip connections, the attention mechanism proposed by the main article could be better understood by analyzing the behaviour of ResNets and DenseNets.
Thinking about recent success of residual connections, I think the main strength of He&amp;rsquo;s networks relies in implicit alleviation the &lt;em&gt;single-shot&lt;/em&gt; constraint by letting residual cells &lt;a href=&#34;https://arxiv.org/abs/1605.06431&#34; target=&#34;_blank&#34;&gt;behave like ensembles of relatively shallow networks&lt;/a&gt;.
If we would follow the structural suggestions of the nature for vision systems, we could define a lower level attention mechanism that could decide which visual patch should be revised by which processing cell or sub-network.
Furthermore, if we dare to experiment with incorporating the human vision system we could reuse recent studies on expanding the attention mechanism to the temporal domain, practically speaking: latent layers should allow refinement of the features by simply reiterating on them (recurrent networks).
Why I think this field is promising is that our recognition system models continously the target scene, even if the target is stationary (i.e. an image, or real life scenes where the state can be revealed with a single observation).
We continously process the visual information, focus on different aspects, revise and compare patches.
In contrast, current state of the art feature extractor architectures are trained end-to-end and still generalizing well, still they are constrained to work in a single shot, processing the whole image at once.
It would not replace the feature extractors, but similar&lt;/p&gt;

&lt;p&gt;For well defined examples see previous work on &lt;a href=&#34;https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Liang_Recurrent_Convolutional_Neural_2015_CVPR_paper.pdf&#34; target=&#34;_blank&#34;&gt;Recurrent ConvNets for object recognition&lt;/a&gt;:
&lt;img src=&#34;https://users.itk.ppke.hu/~botcs/about/img/rcnn.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;For recent successful applications of RNNs on top of classic feature extractors see &lt;a href=&#34;https://arxiv.org/abs/1705.03633&#34; target=&#34;_blank&#34;&gt;Inferring and Executing Programs for Visual Reasoning&lt;/a&gt; and &lt;a href=&#34;https://arxiv.org/abs/1603.08507&#34; target=&#34;_blank&#34;&gt;Generating Visual Explanations&lt;/a&gt;:
&lt;img src=&#34;https://users.itk.ppke.hu/~botcs/about/img/reasoning-program.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;proposal&#34;&gt;Proposal&lt;/h2&gt;

&lt;p&gt;There are two main areas that I would like to investigate:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;[short-term]&lt;/code&gt; Generalized benchmark of &lt;em&gt;the underlying attention mechanism&lt;/em&gt; on recent state of the art &lt;em&gt;ImageNet&lt;/em&gt; architectures&lt;/li&gt;
&lt;li&gt;Revision of &lt;em&gt;the underlying attention mechanism&lt;/em&gt; by &lt;a href=&#34;https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Liang_Recurrent_Convolutional_Neural_2015_CVPR_paper.pdf&#34; target=&#34;_blank&#34;&gt;RCNNs&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Let&#39;s use our brains</title>
      <link>https://users.itk.ppke.hu/~botcs/about/talk/pow1/</link>
      <pubDate>Tue, 01 May 2018 22:43:27 +0200</pubDate>
      
      <guid>https://users.itk.ppke.hu/~botcs/about/talk/pow1/</guid>
      <description>

&lt;h2 id=&#34;a-few-moments-from-the-talk&#34;&gt;A few moments from the talk:&lt;/h2&gt;

&lt;p&gt;&lt;center&gt;
&lt;iframe src=&#34;https://www.facebook.com/plugins/video.php?href=https%3A%2F%2Fwww.facebook.com%2Fgalileowebcast%2Fvideos%2F1428878187229525%2F&amp;show_text=0&#34; width=&#34;640&#34; height=&#34;480&#34; style=&#34;border:none;overflow:hidden&#34; scrolling=&#34;no&#34; frameborder=&#34;0&#34; allowTransparency=&#34;true&#34; allowFullScreen=&#34;true&#34;&gt;&lt;/iframe&gt;&lt;/p&gt;

&lt;p&gt;&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://cdn-images-1.medium.com/max/1455/1*XI3beonBnOwp-y5BwNOqCw.gif&#34; alt=&#34;&#34; /&gt;
We have also experimented with style transfer + emotion recognition
&lt;img src=&#34;https://1.bp.blogspot.com/-klSJ83xlhFE/WeIuC-BVHVI/AAAAAAAAIL4/kyLONsOxkiAJG-w7CeAqTt6fxl1sKB3agCLcBGAs/s1600/DSC_0561.JPG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;basics-of-parametrized-supervised-learning&#34;&gt;Basics of parametrized supervised learning&lt;/h3&gt;

&lt;p&gt;(the cogwheels are just the parameters)
&lt;img src=&#34;https://users.itk.ppke.hu/~botcs/about/img/supervised-distance.svg&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;https://users.itk.ppke.hu/~botcs/about/img/forwardbackwardupdate.svg&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;https://users.itk.ppke.hu/~botcs/about/img/forward.svg&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;https://users.itk.ppke.hu/~botcs/about/img/backward.svg&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;https://users.itk.ppke.hu/~botcs/about/img/update.svg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>&#34;What I cannot create, I do not understand&#34;</title>
      <link>https://users.itk.ppke.hu/~botcs/about/talk/pow4/</link>
      <pubDate>Tue, 01 May 2018 21:43:27 +0200</pubDate>
      
      <guid>https://users.itk.ppke.hu/~botcs/about/talk/pow4/</guid>
      <description>

&lt;p&gt;&lt;center&gt;&lt;iframe src=&#34;https://www.facebook.com/plugins/video.php?href=https%3A%2F%2Fwww.facebook.com%2Fgalileowebcast%2Fvideos%2F1557571537693522%2F&amp;show_text=0&amp;width=560&#34; width=&#34;560&#34; height=&#34;315&#34; style=&#34;border:none;overflow:hidden&#34; scrolling=&#34;no&#34; frameborder=&#34;0&#34; allowTransparency=&#34;true&#34; allowFullScreen=&#34;true&#34;&gt;&lt;/iframe&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;h2 id=&#34;a-few-moments-from-the-talk&#34;&gt;A few moments from the talk&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;https://users.itk.ppke.hu/~botcs/about/img/fmri-dl.svg&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;https://users.itk.ppke.hu/~botcs/about/img/dental-sr.svg&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;https://users.itk.ppke.hu/~botcs/about/img/mi4-banner.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Machines learning on their own</title>
      <link>https://users.itk.ppke.hu/~botcs/about/talk/pow2/</link>
      <pubDate>Tue, 01 May 2018 21:43:27 +0200</pubDate>
      
      <guid>https://users.itk.ppke.hu/~botcs/about/talk/pow2/</guid>
      <description>

&lt;h2 id=&#34;a-few-moments-from-the-talk&#34;&gt;A few moments from the talk&lt;/h2&gt;

&lt;p&gt;&lt;center&gt;&lt;/p&gt;

&lt;iframe src=&#34;https://www.facebook.com/plugins/video.php?href=https%3A%2F%2Fwww.facebook.com%2Fgalileowebcast%2Fvideos%2F1454249364692407%2F&amp;show_text=0&amp;width=560&#34; width=&#34;560&#34; height=&#34;315&#34; style=&#34;border:none;overflow:hidden&#34; scrolling=&#34;no&#34; frameborder=&#34;0&#34; allowTransparency=&#34;true&#34; allowFullScreen=&#34;true&#34;&gt;&lt;/iframe&gt;

&lt;p&gt;&lt;/center&gt;
&lt;img src=&#34;https://users.itk.ppke.hu/~botcs/about/img/robotteach.svg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;seq2seq&#34;&gt;&lt;code&gt;seq2seq&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://users.itk.ppke.hu/~botcs/about/img/seq2seq.svg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;clustering-instead-of-discrimination&#34;&gt;Clustering instead of discrimination&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://users.itk.ppke.hu/~botcs/about/img/nocluster.svg&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;https://users.itk.ppke.hu/~botcs/about/img/cluster.svg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;gans&#34;&gt;GANs&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://users.itk.ppke.hu/~botcs/about/img/gan.svg&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;https://users.itk.ppke.hu/~botcs/about/img/gan-loss.svg&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;https://users.itk.ppke.hu/~botcs/about/img/gan-loss-multi.svg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;more-and-more-people-got-interested-in-ai&#34;&gt;More and more people got interested in AI&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;mi2-banner.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>What would Prometheus bring today?</title>
      <link>https://users.itk.ppke.hu/~botcs/about/talk/pow5/</link>
      <pubDate>Tue, 01 May 2018 21:43:27 +0200</pubDate>
      
      <guid>https://users.itk.ppke.hu/~botcs/about/talk/pow5/</guid>
      <description>

&lt;p&gt;Thinking about recent speedup in the field of AI by incorporating our observations of natural learning dynamics will change not just the game of finance, medicine, law and education, but our daily lives as well.&lt;/p&gt;

&lt;p&gt;To emphasize it we draw an analogy between the usage of fire.
Our talk had two main axes:
Humanity have a long history of using something, actually way before understanding it - e.g. our digestion system has already evolved in such a way that we are no longer able to digest raw food, while until the 19th century it was not well defined what does actually happen inside.
Secondly, fire is natural power that is nor good neither evil, still this neutrality could be used to warm our home and destroy cities. Still we do not applause nor blame the fire for either.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;iframe src=&#34;https://www.facebook.com/plugins/video.php?href=https%3A%2F%2Fwww.facebook.com%2Fgalileowebcast%2Fvideos%2F1619302464853762%2F&amp;show_text=0&amp;width=560&#34; width=&#34;560&#34; height=&#34;315&#34; style=&#34;border:none;overflow:hidden&#34; scrolling=&#34;no&#34; frameborder=&#34;0&#34; allowTransparency=&#34;true&#34; allowFullScreen=&#34;true&#34;&gt;&lt;/iframe&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;h2 id=&#34;a-few-moments-from-the-talk&#34;&gt;A few moments from the talk&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;https://users.itk.ppke.hu/~botcs/about/img/mi5-banner.svg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://users.itk.ppke.hu/~botcs/about/img/mi5-banner-alt.jpg&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;https://users.itk.ppke.hu/~botcs/about/img/mi5-final.svg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
